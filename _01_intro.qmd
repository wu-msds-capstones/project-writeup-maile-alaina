# Abstract

This capstone project investigates the diagnostic accuracy of generative AI, specifically ChatGPT, in a telehealth setting. The study compares AI-generated diagnoses with those provided by human clinicians, assessing the feasibility of using AI for accurate medical diagnosis. A dataset licensed from MIT and sourced from Kaggle, containing over one hundred symptoms associated with various diagnoses, was employed. ChatGPT simulated a telehealth doctor, generating diagnostic predictions based on randomized symptom data. These predictions were then compared to actual diagnoses to evaluate accuracy.

The findings reveal that while ChatGPT demonstrated moderate accuracy in grouping symptoms within the same medical family, it achieved an overall diagnostic accuracy of only 25.15%, indicating significant limitations in delivering precise and reliable diagnoses. Traditional machine learning models, such as Decision Trees and Logistic Regression, outperformed ChatGPT with a higher accuracy of 57%, underscoring the importance of targeted, data-driven approaches for clinical diagnostics.

The study highlights the potential of generative AI to assist in preliminary diagnostic processes but emphasizes the need for further refinement and the integration of real-world clinical data to ensure its reliability. Ethical considerations, including data privacy, bias mitigation, and the necessity of human oversight, are critical for the responsible deployment of AI in healthcare. Future research should focus on enhancing AI model accuracy, developing hybrid AI-human diagnostic systems, and addressing ethical challenges to fully harness the transformative potential of AI in healthcare diagnostics.

# Introduction

Generative AI is rapidly emerging as a transformative technology in the field of healthcare, with the potential to significantly enhance diagnostic processes. Unlike traditional AI models, which are typically designed to classify or predict outcomes based on existing data, generative AI models have the ability to create new data by learning patterns from vast datasets. This capability enables generative AI to analyze large volumes of patient information swiftly and identify patterns that may be challenging for human clinicians to discern. The promise of generative AI lies in its potential to deliver faster, more consistent, and potentially more accurate diagnoses.

However, the integration of generative AI into healthcare brings forth critical questions regarding its practical application in clinical settings. A key concern is the accuracy of AI-generated diagnoses compared to those made by human clinicians when presented with identical symptoms. Can generative AI achieve the high level of accuracy required for clinical use? What are its strengths and limitations in this context?

This capstone project aims to evaluate the diagnostic accuracy of generative AI, specifically ChatGPT, within a telehealth setting. By comparing AI-generated diagnoses with those provided by human clinicians, this study seeks to assess the feasibility of using AI for accurate medical diagnoses. Additionally, the research explores the broader impact of generative AI on improving diagnostic processes and patient outcomes.

To achieve these objectives, we utilized a dataset licensed from the Massachusetts Institute of Technology (MIT) and sourced from Kaggle, which includes over one hundred symptoms associated with various diagnoses. ChatGPT was employed to simulate a telehealth doctor through multiple API calls, where it generated diagnostic predictions based on randomized symptom data. These AI predictions were then compared to the actual diagnoses in the dataset to assess their accuracy.

The research is structured as follows: First, we review the current state of generative AI in healthcare, highlighting its applications, benefits, and challenges. We then detail our methodology, including data collection, model selection, and statistical analysis. The results of our study are presented next, followed by a discussion of their implications, limitations, and potential future research directions. Finally, we conclude with a summary of our findings and their significance for the future of AI in healthcare.

Through this investigation, we aim to provide valuable insights into the capabilities and limitations of generative AI in healthcare, contributing to the ongoing discussion about its role in the future of medical diagnostics.
