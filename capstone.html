<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.53">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Capstone Project</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="capstone_files/libs/clipboard/clipboard.min.js"></script>
<script src="capstone_files/libs/quarto-html/quarto.js"></script>
<script src="capstone_files/libs/quarto-html/popper.min.js"></script>
<script src="capstone_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="capstone_files/libs/quarto-html/anchor.min.js"></script>
<link href="capstone_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="capstone_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="capstone_files/libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="capstone_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="capstone_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="capstone_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="capstone_files/libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">


</head>

<body class="fullcontent">

<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Capstone Project</h1>
            <p class="subtitle lead">Subtitle</p>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-contents">
               <p>Bob </p>
               <p>Jane </p>
            </div>
    </div>
      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Accurate and timely diagnosis is crucial in healthcare as it directly affects recovery trajectories and patient outcomes. In recent years, advancements in technology, particularly in generative artificial intelligence (AI), have opened up new avenues for transforming the healthcare landscape. One of these new avenues, Generative AI, a subset of AI that can create new data based on patterns learned from existing data, has the potential to revolutionize how diagnoses are made and improve the overall efficiency of healthcare systems.</p>
<p>To set the stage for our investigation, it is essential to understand the role of AI in healthcare and the current state of research in this field. Generative AI can quickly analyze vast amounts of data and identify patterns that may be challenging for human clinicians to discern. This capability promises more accurate and timely diagnoses, which could significantly enhance patient care.</p>
<p>However, a critical question remains: How do the diagnoses from generative AI compare to those made by human clinicians when presented with identical symptoms?</p>
<p>Our capstone project aims to evaluate the accuracy of generative AI in diagnosing medical conditions and explore the feasibility of developing precise diagnostic models using this technology. We seek to determine how well generative AI can perform in real-world scenarios and its potential impact on improving diagnostic processes.</p>
</section>
<section id="background" class="level1">
<h1>Background</h1>
<p>The integration of Generative AI (GAI) into healthcare is transforming the landscape of diagnosis, treatment, and patient care. By leveraging advanced algorithms, GAI generates new data and insights, offering versatile solutions across various applications such as text, images, audio, and video. This revolution in healthcare technology brings numerous benefits but also raises significant questions about the ethical implications, potential biases, and practical applications of these AI-driven tools.</p>
<p>This document delves into the extensive scoping review conducted to understand the current state and potential of GAI in healthcare. Through this analysis, we aim to highlight both the advantages and challenges associated with the adoption of GAI in healthcare, particularly focusing on the ethical considerations and the mitigation of biases inherent in AI systems.</p>
</section>
<section id="background-on-generative-ai-and-healthcare" class="level1">
<h1>Background on Generative AI and Healthcare</h1>
<p>Generative AI (GAI) is revolutionizing healthcare by offering innovative solutions for diagnosis, treatment, and patient care. This advanced form of artificial intelligence enhances healthcare delivery by generating new data and insights, providing a versatile tool for various applications including text, images, audio, and video. However, its integration into healthcare systems raises questions about its benefits, challenges, and practical applications.</p>
<p>In a comprehensive scoping review following PRISMA-ScR guidelines, researchers searched databases like Web of Science, PubMed, and Scopus, ultimately including 109 articles from an initial pool of 1406. The study identified nine prominent GAI models, with ChatGPT, Google Bard, and Microsoft Bing AI being the most frequently utilized in healthcare settings.</p>
<p>Generative AI has several key applications in healthcare. It supports clinical decision-making by aiding in the diagnosis and prediction of diseases, triage, treatment strategy formulation, and offering management advice. It also plays a vital role in medical education by providing insights on health conditions, designing exam questions, producing medical articles, and supporting interactive learning tools for medical students. Additionally, GAI streamlines clinical documentation by summarizing patient problems, creating discharge summaries, and generating healthcare-related text and reports.</p>
<p>The benefits of generative AI in healthcare are significant. It improves diagnosis accuracy, reduces human error, and efficiently analyzes symptoms to identify treatment options. GAI provides rapid access to valuable insights, offers high concordance rates with specialists’ recommendations, and enhances patient engagement through personalized care. It also supports medical research and education by assisting in article drafting and clinical trial matching, promoting a better understanding of complex medical concepts. Furthermore, GAI offers substantial time and cost savings compared to traditional evaluations, reducing the workload for medical professionals.</p>
<p>However, generative AI in healthcare also faces several challenges. While it cannot replace human doctors or account for individual patient preferences, it may exhibit biases and variability in human adjudication, leading to lower accuracy in some diagnoses and treatment recommendations. Ethical considerations and data privacy issues are also significant, with risks of AI generating inaccurate or biased information. Additionally, patients may lack confidence in AI accuracy, necessitating frequent human oversight and modifications. Continuous validation and updating are necessary to maintain performance and reliability, and there is a need for specific training and re-training of AI models in various medical contexts.</p>
<p>Generative AI has also shown promise in remote patient monitoring (RPM) telehealth solutions. Companies like Andor Health and Babylon Health, as well as healthcare professionals such as Dr.&nbsp;Josh Tamayo-Sarver, utilize ChatGPT to enhance virtual health interactions, patient communication, and routine healthcare tasks. ChatGPT answers patient questions, monitors symptoms, provides personalized health education, offers emotional support, and overcomes language barriers, making healthcare more accessible and efficient. Its integration into telemedicine offers enhanced patient engagement, streamlined workflows, expanded accessibility, cost savings, and data-driven insights. Despite its benefits, concerns about accuracy, reliability, lack of human judgment, and patient privacy need addressing. Best practices for implementing GAI in healthcare include training and fine-tuning AI models, ensuring human oversight, adhering to regulatory compliance, conducting thorough testing, and continuous improvement based on feedback.</p>
<p>For readers unfamiliar with this area, some key vocabulary and concepts are important to grasp:</p>
<ul>
<li><strong>Generative AI:</strong> A type of artificial intelligence that generates new data based on patterns from existing data. It is different from other AI systems that might only classify or predict based on provided inputs.</li>
<li><strong>Diagnostic Accuracy:</strong> A measure of how correctly a diagnostic tool identifies or predicts a medical condition compared to a reference standard.</li>
<li><strong>Healthcare Systems Integration:</strong> The process of incorporating new technologies, such as AI, into existing healthcare frameworks.</li>
</ul>
<p>Our research is situated within the broader context of ongoing efforts to integrate AI into healthcare. The current state of research shows a growing interest in leveraging AI for diagnostics, but there is still much to learn about its practical implications and effectiveness. By evaluating the performance of generative AI in this context, we aim to contribute valuable insights that could inform future developments and enhance the role of AI in healthcare diagnostics.</p>
<section id="data-ethics-in-ai-and-healthcare" class="level2">
<h2 class="anchored" data-anchor-id="data-ethics-in-ai-and-healthcare">Data Ethics in AI and Healthcare</h2>
<p>Biases are an inherent risk when working with AI and data-driven projects, particularly in the healthcare domain. The synthetic data sourced from Kaggle might reflect biases present in the original datasets from which it was derived, potentially influencing the representativeness of the data for certain conditions, diagnostic categories, or inherent biases in healthcare based on patient demographics. Additionally, generative AI models, including ChatGPT, can exhibit biases based on their training data, which may include inaccuracies or skewed information about medical conditions.</p>
<section id="bias-in-healthcare-ai" class="level3">
<h3 class="anchored" data-anchor-id="bias-in-healthcare-ai">Bias in Healthcare AI</h3>
<p>In healthcare, these biases can have significant implications. For example, if the training data used to develop AI models includes incomplete or imprecise representations of certain medical conditions, the resulting diagnostic tools may not perform optimally in real-world scenarios. This can impact the accuracy and reliability of diagnoses and potentially affect patient outcomes.</p>
</section>
<section id="mitigating-bias" class="level3">
<h3 class="anchored" data-anchor-id="mitigating-bias">Mitigating Bias</h3>
<p>To address these concerns, we have undertaken measures to identify and mitigate potential biases in our project. This involves analyzing the quality and comprehensiveness of the datasets and evaluating the AI’s performance to ensure that our findings are as accurate and reliable as possible. This includes:</p>
<ul>
<li><strong>Data Quality Analysis:</strong> Ensuring the datasets are comprehensive and representative of diverse patient populations.</li>
<li><strong>Bias Detection:</strong> Implementing techniques to detect and quantify biases in the data and AI models.</li>
<li><strong>Performance Evaluation:</strong> Testing AI models across various demographic groups to ensure equitable performance.</li>
</ul>
</section>
<section id="ethical-considerations" class="level3">
<h3 class="anchored" data-anchor-id="ethical-considerations">Ethical Considerations</h3>
<p>Although we used synthetic and generative data, it is also important to note that in real-world scenarios involving actual patient data, obtaining informed consent is crucial. Our project did not involve real patient data, but if it had, we would have implemented measures to obtain explicit consent from individuals whose data was used, ensuring that they were fully aware of how their data would be utilized.</p>
</section>
<section id="informed-consent" class="level3">
<h3 class="anchored" data-anchor-id="informed-consent">Informed Consent</h3>
<p>In real-world applications, informed consent involves:</p>
<ul>
<li><strong>Transparency:</strong> Clearly explaining how the data will be used and the purposes of the AI models.</li>
<li><strong>Voluntariness:</strong> Ensuring participation is voluntary and that individuals can withdraw their consent at any time.</li>
<li><strong>Comprehension:</strong> Providing information in an understandable manner so that individuals can make informed decisions.</li>
</ul>
</section>
<section id="broader-ethical-implications" class="level3">
<h3 class="anchored" data-anchor-id="broader-ethical-implications">Broader Ethical Implications</h3>
<p>The integration of AI in healthcare comes with broader ethical considerations, including the potential impact on healthcare professionals and patient trust. We considered these implications by evaluating not only the technical accuracy of the AI but also its potential effects on the broader healthcare ecosystem. Our aim was to ensure that the use of AI enhances, rather than undermines, the quality of patient care and the role of healthcare providers.</p>
</section>
<section id="enhancing-patient-care" class="level3">
<h3 class="anchored" data-anchor-id="enhancing-patient-care">Enhancing Patient Care</h3>
<ul>
<li><strong>Augmenting Healthcare Providers:</strong> Using AI to support and enhance the capabilities of healthcare professionals, not replace them.</li>
<li><strong>Building Trust:</strong> Ensuring transparency and explainability in AI decisions to build trust with patients and providers.</li>
<li><strong>Continuous Monitoring:</strong> Regularly updating and monitoring AI models to maintain their accuracy and reliability over time.</li>
</ul>
<p>By addressing these ethical considerations, we aim to develop AI tools that are not only technically sound but also ethically responsible, ultimately contributing to better healthcare outcomes and maintaining the trust of patients and healthcare providers.</p>
</section>
</section>
</section>
<section id="references" class="level1">
<h1>References</h1>
<p>Moulaei, K., Yadegari, A., Baharestani, M., Farzanbakhsh, S., Sabet, B., &amp; Reza Afrash, M. (2024). Generative artificial intelligence in healthcare: A scoping review on benefits, challenges and applications. International Journal of Medical Informatics, 188, 105474. https://doi.org/10.1016/j.ijmedinf.2024.105474&nbsp;</p>
<p>Temsah MH, Jamal A, Alhasan K, Aljamaan F, Altamimi I, Malki KH, Temsah A, Ohannessian R, Al-Eyadhy A. Transforming Virtual Healthcare: The Potentials of ChatGPT-4omni in Telemedicine. Cureus. 2024 May 30;16(5):e61377. doi: 10.7759/cureus.61377. PMID: 38817799; PMCID: PMC11139454.&nbsp;</p>
</section>
<section id="methods" class="level1">
<h1>Methods</h1>
<p>We started by selecting a dataset licensed from the Massachusetts Institute of Technology (MIT), where each row indicates the presence or absence of over one hundred symptoms associated with a single diagnosis. Using this dataset, we developed multiple API calls utilizing ChatGPT, a popular generative AI platform, to act as a tele-health doctor. For each row in our dataset, the API presented ChatGPT with a randomized order of symptoms that tested positive and requested its diagnosis estimation. Following the API’s execution, we compared ChatGPT’s diagnosis with the diagnosis provided in the source dataset. To assess accuracy, we applied a scoring system: one point for an incorrect and unrelated diagnosis, two points for an incorrect but related diagnosis, and three points for a correct diagnosis. This methodology enabled us to evaluate the effectiveness of ChatGPT in accurately predicting diagnoses based on symptom data.</p>
<section id="data-engineering" class="level2">
<h2 class="anchored" data-anchor-id="data-engineering">Data Engineering</h2>
<p>Our data collection process involved several stages and sources. Initially, we sourced synthetic symptom and prognosis data from Kaggle. This provided a foundational dataset for our project. To expand and enrich this dataset, we utilized the ChatGPT API to generate additional data. Specifically, we generated diagnosis estimations through ChatGPT, which served as our primary generative AI tool for this project. Alongside the diagnosis estimations, we also recorded an accuracy score ranging from 1 to 3. This score was used to evaluate the performance of ChatGPT in terms of its diagnostic accuracy.</p>
<section id="data" class="level3">
<h3 class="anchored" data-anchor-id="data">Data</h3>
<p>Our first dataset, the synthetic source, was sourced from a Disease Prediction Using Machine Learning on Kaggle.com, a data science competition platform and online community for data scientists and machine learning practitioners. The dataset comprises two primary CSV files—one for training and another for testing. Each file contains 133 columns, with 132 columns representing different symptoms experienced by patients and the final column denoting the disease prognosis. This structure supports the development of models capable of predicting 42 distinct diseases based on the given symptoms.</p>
<p>The dataset’s main goal is to enable the creation of machine learning models that can accurately predict diseases based on a wide array of symptoms. By mapping 132 parameters to 42 different diseases, the dataset provides an extensive framework for applying machine learning to medical science, ultimately aiming to streamline the diagnostic process for healthcare professionals.</p>
<section id="content-breakdown" class="level4">
<h4 class="anchored" data-anchor-id="content-breakdown">Content Breakdown</h4>
<p><strong>Columns:</strong> The dataset includes 133 columns: - 132 columns representing various symptoms (e.g., itching, skin rash, continuous sneezing, joint pain). - 1 column for disease prognosis indicating the disease corresponding to the symptoms.</p>
<p><strong>Files:</strong> The dataset comprises two files: - Training.csv: Used to train machine learning models. - Testing.csv: Used to evaluate the performance of the trained models.</p>
</section>
</section>
<section id="data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="data-augmentation">Data Augmentation</h3>
<p>To understand how generative AI can impact prognosis diagnosing, we recognized that our original dataset was insufficient. Therefore, we augmented our data by comparing the accuracy between our initial dataset and generative AI outputs. We did this by making a series of API calls using OpenAI with the AI acting as a virtual doctor.</p>
<section id="api-key-setup" class="level4">
<h4 class="anchored" data-anchor-id="api-key-setup">API Key Setup</h4>
<p>We selected OpenAI for this project because its API allows developers to integrate advanced language features such as text completion, translation, and summarization into their applications. OpenAI’s versatility in chatbots, virtual assistants, and content creation makes it ideal for providing intelligent and context-aware interactions. In our case, we used OpenAI to simulate a doctor’s role.</p>
</section>
<section id="model-selection" class="level4">
<h4 class="anchored" data-anchor-id="model-selection">Model Selection</h4>
<p>We utilized the “gpt-3.5-turbo” model, an advanced language model from OpenAI known for its efficiency and enhanced capabilities. This model offers improved performance and faster response times compared to its predecessors. It is designed to understand and generate human-like text, making it suitable for a variety of applications including chatbots, content creation, and language translation. We chose this model for its ability to handle complex language tasks with high accuracy, making it a powerful tool for integrating sophisticated language processing into our project.</p>
</section>
</section>
<section id="initial-diagnosis-call" class="level3">
<h3 class="anchored" data-anchor-id="initial-diagnosis-call">Initial Diagnosis Call</h3>
<p>Our first API call involved instructing the AI to act as a doctor. We provided the following prompt to the GPT-3.5-turbo model:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">"Pretend you are a doctor. Patient presents to you with symptoms: {' '.join(symptoms)}. Predict the primary diagnosis concisely using ten words or less."</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This was used to determine if the generative AI would reach the same conclusion as our sample dataset regarding the ailment based on a randomized order of symptoms.</p>
</section>
<section id="accuracy-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-evaluation">Accuracy Evaluation</h3>
<p>Next, we evaluated the newly predicted prognosis using a custom function get_rating. This function sends a prognosis and its predicted values to the GPT-4 API and receives a rating based on the match accuracy. The rating scale ranges from 1 to 3:</p>
<ol type="1">
<li><p>No match</p></li>
<li><p>Same family</p></li>
<li><p>Perfect match</p></li>
</ol>
<p>The evaluation prompt was:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_rating(prognosis, predicted_values):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> (</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"Prognosis: </span><span class="sc">{</span>prognosis<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"Predicted Values: </span><span class="sc">{</span>predicted_values<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Rate the predicted values on a scale of 1 to 3 where 1 means no match, 2 means in the same family, and 3 means perfect match. "</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Respond with only the number."</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="medical-family-determination" class="level3">
<h3 class="anchored" data-anchor-id="medical-family-determination">Medical Family Determination</h3>
<p>Finally, we determined the medical “family” for both the original prognosis and the generative AI prognosis using these prompts:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>Predicted Values: {predicted_values}</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>Determine the medical family this prognosis belongs to.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>Prognosis: {prognosis}</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>Determine the medical family this prognosis belongs to.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="new-feature-creation" class="level3">
<h3 class="anchored" data-anchor-id="new-feature-creation">New Feature Creation</h3>
<p>As mentioned prior, due to the API calls, the following new features (columns) were created:</p>
<ul>
<li><p>Predicted Values</p></li>
<li><p>Rating</p></li>
<li><p>Medical Family</p></li>
<li><p>Predicted Family</p></li>
</ul>
<p>Based on these new features, we also created the following new “calculated columns” to determine a match between the original data and the generative AI data. These features include:</p>
<ul>
<li><p>match_found</p></li>
<li><p>match_found_family</p></li>
</ul>
<p>This was done in R by adding a new column to the dataset to check if there are any matching words between the prognosis and predicted values. This helps identify if the predicted prognosis contains any terms that appear in the actual prognosis.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>ds2<span class="ot">=</span>ds2 <span class="sc">%&gt;%</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">match_found =</span> <span class="fu">mapply</span>(<span class="cf">function</span>(x, y) {</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    words1 <span class="ot">&lt;-</span> <span class="fu">str_split</span>(x, <span class="st">" "</span>)[[<span class="dv">1</span>]]</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    words2 <span class="ot">&lt;-</span> <span class="fu">str_split</span>(y, <span class="st">" "</span>)[[<span class="dv">1</span>]]</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.integer</span>(<span class="fu">any</span>(words1 <span class="sc">%in%</span> words2))</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  }, prognosis, predicted_values))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="data-cleaning" class="level2">
<h2 class="anchored" data-anchor-id="data-cleaning">Data Cleaning</h2>
<p>Data cleaning and preprocessing were essential to ensure the quality and reliability of our dataset. We made several assumptions during this process, including the accuracy of the synthetic data from Kaggle and the consistency of the accuracy scores provided by ChatGPT. After all of the new features were created, all inconsistencies or errors identified during the cleaning process were addressed to maintain the integrity of the data.</p>
<p>These inconsistencies included our new features being too wordy, with the new “predicted diagnosis” including the scale along with the diagnosis. We then extracted the scale from the feature so that the output would only include the diagnosis.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">setwd</span>(<span class="st">"/Users/alainaholland/Documents/Github/project-workbook-maile-alaina/Data"</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>ds <span class="ot">=</span> <span class="fu">read.csv</span>(<span class="st">"data_with_scale.csv"</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(ds<span class="sc">$</span>predicted_values,<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Possible diagnosis: Pityriasis versicolor or tinea versicolor."                               
[2] "Possible diagnosis: Dermatitis herpetiformis, linked to gluten sensitivity or celiac disease."
[3] "Possible diagnosis: Dermatitis herpetiformis, a form of celiac disease rash."                 
[4] "Likely diagnosis: Dermatitis or eczema. Further evaluation and treatment needed."             
[5] "Contact dermatitis from allergen exposure."                                                   </code></pre>
</div>
</div>
<p>Furthermore, we noted that in the original dataset, there were several replicates of the same symptoms and diagnosis. Originally, we considered removing all the duplicates but then decided instead to randomize the order of the symptoms since the dataset only included 41 prognosis.</p>
</section>
<section id="data-storage" class="level2">
<h2 class="anchored" data-anchor-id="data-storage">Data Storage</h2>
<p>For the effective organization and future reference of our data, we have utilized a GitHub repository. This repository not only allows us to manage version control efficiently but also provides a centralized location for accessing and referring to various components of our project throughout its development and documentation.</p>
<section id="repository-structure-and-purpose" class="level3">
<h3 class="anchored" data-anchor-id="repository-structure-and-purpose">Repository Structure and Purpose</h3>
<p>Our GitHub repository is organized into several directories, each serving a specific purpose and rationale to streamline our workflow and enhance collaboration. The .github directory contains GitHub-specific configurations essential for automating workflows, managing issues, and incorporating feedback from GitHub Classroom. The Data directory centralizes all raw and processed datasets, simplifying data management and ensuring consistency and accuracy across various stages of the project. The Data_Engineering directory includes scripts and resources for data engineering tasks such as preprocessing and transformation, maintaining clarity and facilitating reproducibility and debugging. The Documentation directory houses project documentation, reports, and other written materials, supporting effective communication and collaboration. The Machine_Learning directory consolidates all machine learning-related components, making it easier to track model development, training processes, and performance evaluations. The .DS_Store file, automatically generated by macOS, is included to avoid unnecessary clutter and ensure the repository reflects the actual file system. Finally, the README.md file serves as the entry point for anyone accessing the repository, providing a comprehensive overview of the project and guiding users through the repository structure with essential information about the project’s goals and resources.</p>
<ul>
<li><strong>.github</strong>: Contains GitHub-specific configurations and feedback from GitHub Classroom.</li>
<li><strong>Data</strong>: Stores raw and processed datasets used in the project.</li>
<li><strong>Data_Engineering</strong>: Includes scripts and resources for data engineering tasks such as preprocessing and transformation.</li>
<li><strong>Documentation</strong>: Contains project documentation, reports, and other written materials.</li>
<li><strong>Machine_Learning</strong>: Houses machine learning models, training scripts, and evaluation metrics.</li>
<li><strong>.DS_Store</strong>: A system file related to macOS directory management.</li>
<li><strong>README.md</strong>: Provides an overview of the project, including the research question, project description, and links to additional resources.</li>
</ul>
</section>
</section>
<section id="statistical-methodology" class="level2">
<h2 class="anchored" data-anchor-id="statistical-methodology">Statistical Methodology</h2>
<p>We employed a comprehensive statistical methodology to evaluate the performance of generative AI (ChatGPT) in diagnosing medical conditions. Our approach included descriptive statistics, accuracy metrics, various statistical tests, error analysis, and bias and variability analysis. Here’s an overview of the statistical methods used:</p>
<ol type="1">
<li><p><strong>Descriptive Statistics:</strong> To summarize the central tendency and dispersion of accuracy scores, we calculated the mean, median, mode, standard deviation, and variance. This provided a foundational understanding of the distribution of diagnostic accuracy ratings.</p></li>
<li><p><strong>Confusion Matrix:</strong> We used a confusion matrix to visualize the AI model’s performance by showing the counts of true positives, true negatives, false positives, and false negatives. This helped in understanding the model’s strengths and weaknesses in classification tasks.</p></li>
<li><p><strong>Accuracy Metrics:</strong> We calculated precision, recall, and F1 scores to evaluate the model’s performance. Precision and recall provided insights into the model’s ability to correctly identify positive cases, while the F1 score balanced these metrics to give an overall performance measure.</p></li>
<li><p><strong>Chi-Square Test:</strong> To determine if there was a significant difference between the expected and observed frequencies of diagnostic accuracy categories, we conducted a chi-square test. This helped us assess the model’s performance consistency across different diagnostic categories.</p></li>
<li><p><strong>McNemar’s Test:</strong> McNemar’s test was used to compare the AI model’s predictions with a benchmark or standard (e.g., human clinician’s diagnosis). This test is particularly suited for paired categorical data and helped us understand the significant differences in performance.</p></li>
<li><p><strong>T-Test:</strong> We performed independent t-tests to compare the means of accuracy scores between different groups (e.g., different datasets or methods). This analysis revealed whether there were significant differences in performance across groups.</p></li>
<li><p><strong>Cohen’s Kappa:</strong> Cohen’s kappa was calculated to measure the agreement between the AI model’s predictions and human clinician’s diagnoses. This statistic provided a quantitative measure of inter-rater reliability.</p></li>
<li><p><strong>Error Analysis:</strong> We conducted an error analysis to identify the nature and distribution of discrepancies between the AI’s predictions and the actual diagnoses. This involved categorizing errors to gain insights into specific areas where the AI’s predictions were less accurate.</p></li>
<li><p><strong>Bias and Variability Analysis:</strong> To assess potential biases in predictions and estimate variability, we used bootstrapping methods. This involved generating confidence intervals for our accuracy metrics and identifying any systematic biases in the AI model’s predictions.</p></li>
<li><p><strong>Correlation Analysis:</strong> Correlation analysis was performed to assess the relationships between different features in the dataset and the accuracy of AI predictions. This helped us understand the impact of various features on the model’s performance and identify areas for potential improvement.</p></li>
</ol>
<p>By employing these statistical methods, we comprehensively evaluated the AI’s diagnostic capabilities, providing a robust framework for understanding its accuracy, reliability, and areas for future enhancement. This multi-faceted approach ensured a thorough assessment, contributing valuable insights into the feasibility and effectiveness of using generative AI for healthcare diagnostics.</p>
</section>
<section id="machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning">Machine Learning</h2>
<section id="model-selection-and-development" class="level3">
<h3 class="anchored" data-anchor-id="model-selection-and-development">Model Selection and Development</h3>
<p>We developed multiple machine learning models, including logistic regression, decision trees, random forests, support vector machines (SVM), and neural networks, to diagnose ailments based on the collected and augmented data. Logistic regression served as a baseline model due to its simplicity and interpretability. Decision trees provided a clear visual representation of decision-making processes. Random forests and SVMs are known for their high accuracy and robustness, while neural networks can capture complex patterns in data. By exploring various models, we aimed to leverage their strengths and mitigate their weaknesses, identifying the best-suited algorithm for our dataset.</p>
</section>
<section id="addressing-overfitting-and-validation" class="level3">
<h3 class="anchored" data-anchor-id="addressing-overfitting-and-validation">Addressing Overfitting and Validation</h3>
<p>To ensure our models did not overfit the training data and could generalize well to unseen data, we implemented k-fold cross-validation and pruning techniques. K-fold cross-validation involved repeatedly training and testing the models on different subsets of the data, providing a more reliable estimate of their performance. Pruning, specifically for decision trees, reduced model complexity by removing branches that had little significance, further preventing overfitting. These techniques were crucial for validating our models’ ability to perform well on new, unseen data.</p>
</section>
<section id="model-comparison-and-feature-importance" class="level3">
<h3 class="anchored" data-anchor-id="model-comparison-and-feature-importance">Model Comparison and Feature Importance</h3>
<p>Comparing the performance of different models allowed us to determine the most effective algorithm for diagnosing ailments. The random forest, SVM, and neural network models demonstrated high accuracy, with SVM achieving perfect accuracy in some instances. Analyzing feature importance in the random forest model provided insights into which symptoms were most influential in predicting prognosis. Understanding feature importance helped guide further refinement of telehealth diagnosis platforms by focusing on the most critical indicators.</p>
</section>
</section>
</section>
<section id="data-1" class="level1">
<h1>Data</h1>
<p>Our first dataset, the synthetic source, was sourced from a Disease Prediction Using Machine Learning on Kaggle.com, a data science competition platform and online community for data scientists and machine learning practitioners. The dataset comprises two primary CSV files—one for training and another for testing. Each file contains 133 columns, with 132 columns representing different symptoms experienced by patients, and the final column denoting the disease prognosis. This structure supports the development of models capable of predicting 42 distinct diseases based on the given symptoms.</p>
<section id="content-breakdown-1" class="level2">
<h2 class="anchored" data-anchor-id="content-breakdown-1">Content Breakdown</h2>
<ul>
<li><strong>Columns</strong>: The dataset includes 133 columns:
<ul>
<li>132 columns representing various symptoms (e.g., itching, skin rash, continuous sneezing, joint pain).</li>
<li>1 column for disease prognosis, indicating the disease corresponding to the symptoms.</li>
</ul></li>
<li><strong>Files</strong>: The dataset comprises two files:
<ul>
<li>Training.csv: Used to train machine learning models.</li>
<li>Testing.csv: Used to evaluate the performance of the trained models.</li>
</ul></li>
</ul>
</section>
<section id="data-augmentation-1" class="level2">
<h2 class="anchored" data-anchor-id="data-augmentation-1">Data Augmentation</h2>
<p>To understand how generative AI can impact prognosis diagnosing, we recognized that our original dataset was insufficient. Therefore, we augmented our data by comparing the accuracy between our initial dataset and generative AI outputs. We did this by making a series of API calls using OpenAI, with the AI acting as a virtual doctor.</p>
</section>
<section id="new-feature-creation-1" class="level2">
<h2 class="anchored" data-anchor-id="new-feature-creation-1">New Feature Creation</h2>
<p>As mentioned prior due to the API calls, the following new features (columns) were created they include “Predicted Values”, “Rating”, “Medical Family”, and “Predicted Family”. Based on these new features, we also created the following new “calculated columns” to determine a match between the original data and the generative AI data. These features include “match_found” and “match_found_family”.</p>
<p>It was done in R by adding a new column to the dataset to check if there are any matching words between the prognosis and predicted values. This helps identify if the predicted prognosis contains any terms that appear in the actual prognosis.</p>
<p>```r ds2 = ds2 %&gt;% mutate(match_found = mapply(function(x, y) { words1 &lt;- str_split(x, ” “)[[1]] words2 &lt;- str_split(y,” “)[[1]] as.integer(any(words1 %in% words2)) }, prognosis, predicted_values))</p>
</section>
</section>
<section id="conclusions" class="level1">
<h1>Conclusions</h1>
<p>Our project aimed to assess the performance of generative AI, specifically ChatGPT, in the context of healthcare diagnostics. We evaluated the AI’s diagnostic accuracy and conducted a detailed error analysis to understand its efficacy and limitations.</p>
<p>The results of our analysis indicate that ChatGPT’s diagnostic capabilities show promise but are not yet entirely accurate. Our diagnostic accuracy assessment revealed that while the AI could group symptoms effectively, achieving exact matches with original diagnoses was less frequent. The use of a match scale (1-3) demonstrated that the AI often aligned within the same diagnostic group but often fell short of precise accuracy.</p>
<p>Our analyses highlighted both the strengths and weaknesses of ChatGPT in diagnostic scenarios. While the AI provides valuable insights and can suggest plausible directions for further diagnosis, it does not yet offer the level of accuracy required for definitive diagnostic purposes.</p>
<p>To extend this research, future projects could focus on: 1. <strong>Enhancing Accuracy</strong>: Further development and training of AI models to improve their diagnostic precision. 2. <strong>Broader Data Integration</strong>: Incorporating more diverse and comprehensive datasets to reduce biases and enhance the AI’s generalizability. 3. <strong>Clinical Validation</strong>: Conducting studies in real clinical settings to evaluate the AI’s performance in practical, high-stakes environments.</p>
<p>Alternatively, if these technological advancements do not achieve the desired accuracy, exploring alternative methods or augmenting AI with additional diagnostic tools might be worthwhile. This would ensure that time and resources are invested in avenues that offer the most significant potential for advancing diagnostic capabilities.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>