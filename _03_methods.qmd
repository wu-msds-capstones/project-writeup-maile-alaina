# Methods

## Dataset Selection and API Development

### Dataset Selection: 

We selected a dataset licensed from the Massachusetts Institute of Technology (MIT), which contains over one hundred symptoms associated with various diagnoses. The dataset includes both training and testing sets, each with 132 symptom columns and one prognosis column.

### API Development: 

We developed multiple API calls utilizing ChatGPT, a popular generative AI platform, to act as a tele-health doctor. For each row in our dataset, the API presented ChatGPT with a randomized order of symptoms that tested positive and requested its diagnosis estimation.

 ![**Figure 2: Flowchart of Dataset Selection and API Development Process.**](images/figure_2.png)





## Data Engineering

### Data Collection: 

Our data collection process involved several stages and sources:

1. **Synthetic Data from Kaggle:** We sourced synthetic symptom and prognosis data from Kaggle's “Disease Prediction Using Machine Learning” competition.
2 **ChatGPT API Calls:** We utilized the ChatGPT API to generate additional data by requesting diagnosis estimations based on the given symptoms.
3. **Data Augmentation:** To understand the impact of generative AI on prognosis diagnosing, we augmented our data by comparing the accuracy between the initial dataset and generative AI outputs through API calls using OpenAI.

 

 ![**Figure 3: Flowchart of Datset Augmentation Approach.**](images/figure_3.png)

### Model Selection and Evaluation

**Model Selection:** We utilized the “gpt-3.5-turbo” model from OpenAI, known for its efficiency and enhanced capabilities. This model was chosen for its ability to handle complex language tasks with high accuracy.

**Initial Diagnosis Call:** Our first API call involved instructing the AI to act as a doctor with the following prompt:  *"Pretend you are a doctor. Patient presents to you with symptoms: {symptoms}. Predict the primary diagnosis concisely using ten words or less."*

**Accuracy Evaluation:** We evaluated the predicted prognosis using a custom function get_rating that sends a prognosis and its predicted values to the GPT-4 API and receives a rating based on match accuracy. 

The rating scale ranges from 1 to 3:

                1. No match
                2. Same family
                3. Perfect match

**Medical Family Determination:** We determined the medical “family” for both the original prognosis and the generative AI prognosis using specific prompts to categorize them.

### Data Cleaning

Data cleaning and preprocessing were essential to ensure the quality and reliability of our dataset. 
Key steps included:

- Addressing inconsistencies or errors.
- Extracting scales from the “predicted diagnosis” to include only the diagnosis.
- Randomizing the order of symptoms to account for replicates.

### Data Storage
We utilized a GitHub repository for the effective organization and future reference of our data, enabling efficient version control and centralized access.

**Repository Structure:**

- **.github:** GitHub-specific configurations.
- **Data:** Stores raw and processed datasets.
- **Data_Engineering:** Scripts and resources for data engineering tasks.
- **Documentation:** Project documentation, reports, and written materials.
- **Machine_Learning:** Machine learning models, training scripts, and evaluation metrics.
- **Statistics:** Statistical modeling, scripts, and evaluation metrics.
- **README.md**: Overview of the project, research question, project description, and links to additional resources.

## Statistical Methodology

1. **Summary Statistics:** To summarize the central tendency and dispersion of accuracy scores, we calculated the mean, median, mode, standard deviation, and variance.
2. **Confusion Matrix:** We used a confusion matrix to visualize the AI model’s performance by showing the counts of true positives, true negatives, false positives, and false negatives.
3. **Chi-Square Test:** To determine if there was a significant difference between the expected and observed frequencies of diagnostic accuracy categories, we conducted a chi-square test.
4. **Correlation Analysis:** Correlation analysis was performed to assess the relationships between different features in the dataset and the accuracy of AI predictions.

## Machine Learning
To see how difficult it was to create an accurate prediction based on a list of symptoms, we decided to create our own in-house machine learning model to foresee the potential pain points of creating accurate diagnoses.

### Model Selection and Development:

We attempted multiple machine learning models, including logistic regression, decision trees, random forests, support vector machines (SVM), and neural networks to diagnose ailments. Before ultimatly landing on a logistic regression due to **MORE**

### Addressing Overfitting and Validation:

**ADD MORE HERE**
